---
title: "Preliminary Analysis"
format: html
author: "Vishnu, Mia, and Julia"
editor: visual
---

```{r}
library(tidyverse)
library(gtsummary)
library(ggplot2)
library(psych)
library(cluster)
library(factoextra)
library(dplyr)
library(reticulate)
```

# Introduction and Data

The data set includes statistics from the 2024 Division 1 and 3 Men’s and Women’s Ultimate Frisbee Championships. The statistics were found on USA Ultimate, the non-profit organization serving as the governing body for ultimate in the United States, and were taken from a data visualization titled “USA Ultimate 2024 Nationals Stats Dashboard”, which was created by Ben Ayres. The data set includes 1665 rows which each correspond to an individual player, and it includes 15 variables which categorize the players by Division, Gender, and Team, and provide game statistics for each player. 

Ultimate frisbee is a sport growing in popularity at the collegiate level and within the Vassar student body as well. However, not much data analysis is available for Ultimate compared to other popular sports. We want to fit a model that would help players analyze their game performance. Therefore, via linear, LASSO, and ridge regression we will fit a prediction model that we train under supervised conditions to be able to predict a player’s plus/minus score (AKA individual impact) based on the variables turns_per_game, ds_per_game, ast_per_game, and pts_per_game. These variables all relate to a player's effectiveness on the field, which is why we will use them to predict pls_mns_per_game. We will also stratify by division and gender, so that we ensure that we have an accurate model for each group. We will have four models in the final product, DI Men, DI Women, DIII Men, and DIII Women.

Since the data was already pretty clean, we did not have to do much data tidying. We just did some string manipulation to extract the school name from the team name, creating a new column called 'school', and had to convert some character variables to factors.

```{r}
ultimate_data <- suppressMessages(read_csv("/Users/miazottoli/Desktop/M244-Final-JVM/data/ulti_clean.csv"))
```

# Methodology

### *Summary Statistics*

```{r}
ultimate_data %>% select(-c(player, team_name)) %>% gtsummary::tbl_summary()
```

```{r}
summary_data <- ultimate_data[, c("pls_mns_per_game", "turns_per_game", "ds_per_game", "ast_per_game", "pts_per_game")]

summary(summary_data)
```

```{r}
describe(summary_data)
```

```{r}
cor(summary_data, use = "complete.obs")
```

```{r}
pairs(summary_data, main = "Pairwise Plots of Ultimate Stats")
```

### *Visualizations/EDA*

```{r gender-&-plus-minus}
# Plot player's plus-minus scores and their gender
ggplot(ultimate_data, aes(x = gender, y = plus_minus, fill = gender)) +
  geom_boxplot() +
  labs(
    title = "Gender vs. Player's +/- Score",
    x = "Gender",
    y = "Player's +/- Score"
  ) +
  theme_minimal()

# Filter table to create a new table called d3 that only contains d3 level players
d3 <- ultimate_data[ultimate_data$level == "Division 3",]

# Plot  Division 3 level player's plus-minus scores and their gender
ggplot(d3, aes(x = gender, y = plus_minus, fill = gender)) +
  geom_boxplot() +
  labs(
    title = "Division 3 Gender vs. Player's +/- Score",
    x = "Gender",
    y = "Player's +/- Score"
  ) +
  theme_minimal()

# Filter table to create a new table called d1 that only contains d3 level players
d1 <- ultimate_data[ultimate_data$level == "Division 1",]

# Plot  Division 1 level player's plus-minus scores and their gender
ggplot(d1, aes(x = gender, y = plus_minus, fill = gender)) +
  geom_boxplot() +
  labs(
    title = "Division 1 Gender vs. Player's +/- Score",
    x = "Gender",
    y = "Player's +/- Score"
  ) +
  theme_minimal()
```

```{r division-level-&-plus-minus}
# Plot player's plus-minus score against the divisional level they are playing in
ggplot(ultimate_data, aes(x = level, y = plus_minus, fill = level)) +
  geom_violin(trim = FALSE) +
  labs(
    title = "Player's +/- Score for Division 1 vs Division 3",
    x = "Division",
    y = "Player's +/- Score"
  ) +
  scale_fill_manual(values = c("Division 1" = "blue", "Division 3" = "pink")) + 
  theme_minimal()

# Filter table to create a new table called women_ultimate_data that only contains female players
women_ultimate_data <- ultimate_data %>%
  filter(gender == "Women")

# Plot female player's plus-minus score against the divisional level they are playing in
ggplot(women_ultimate_data, aes(x = level, y = plus_minus, fill = level)) +
  geom_violin(trim = FALSE) +
  labs(
    title = "Player's +/- Score for Division 1 vs Division 3 Women",
    x = "Division",
    y = "Player's +/- Score"
  ) +
  scale_fill_manual(values = c("Division 1" = "blue", "Division 3" = "pink")) + 
  theme_minimal()

# Filter table to create a new table called men_ultimate_data that only contains male players
men_ultimate_data <- ultimate_data %>%
  filter(gender == "Men")

# Plot male player's plus-minus score against the divisional level they are playing in
ggplot(men_ultimate_data, aes(x = level, y = plus_minus, fill = level)) +
  geom_violin(trim = FALSE) +
  labs(
    title = "Player's +/- Score for Division 1 vs Division 3 Men",
    x = "Division",
    y = "Player's +/- Score"
  ) +
  scale_fill_manual(values = c("Division 1" = "blue", "Division 3" = "pink")) + 
  theme_minimal()
```

```{r plus-minus-&-other-variable}

# Plot a player's plus-minus score and their points per game for the different divisions and genders
ultimate_data %>% ggplot(aes(x = pts_per_game, y = plus_minus, color = division)) + 
   geom_point() + geom_smooth(method = 'lm', se = F) + scale_x_log10() +
  labs(x = "Points per game", y = "Plus/Minus", color = "Division") + 
  theme_minimal() +
  scale_color_viridis_d()

# Plot a player's plus-minus score and their D's per game for the different divisions and genders
ultimate_data %>% ggplot(aes(x = ds_per_game, y = plus_minus, color = division)) + 
   geom_point() + geom_smooth(method = 'lm', se = F)+
  theme_minimal() + scale_x_log10() + 
  labs(x = "Ds per game", y = "Plus/Minus", color = "Division") +
  scale_color_viridis_d()

# Plot a player's plus-minus score and their turns per game for the different divisions and genders
ultimate_data %>% ggplot(aes(x = turns_per_game, y = plus_minus, color = division)) + 
   geom_point() + geom_smooth(method = 'lm', se = F) + scale_x_log10() +
  labs(x = "Turns per game", y = "Plus/Minus", color = "Division") + theme_minimal() +
  scale_color_viridis_d()

# Plot a player's plus-minus score and their assists per game for the different divisions and genders
ultimate_data %>% ggplot(aes(x = ast_per_game, y = plus_minus, color = division)) + 
   geom_point() + geom_smooth(method = 'lm', se = F) + scale_x_log10() +
  labs(x = "Assists per game", y = "Plus/Minus", color = "Division") + theme_minimal() +
  scale_color_viridis_d()
```

```{r PCA}

# Create a dataset df1 by selecting the following the columns below
df1 <- ultimate_data %>% select(c(
  turns_per_game, ds_per_game, pts_per_game, pls_mns_per_game, ast_per_game
))

# Perform principle component analysis on df1 
pam_res <- pam(df1[-4], 3)

# Plots the three clusters
fviz_cluster(pam_res, data = df1[-4],
             geom = "point",
             ellipse.type = "convex",
             palette = "jco",
             ggtheme = theme_minimal()) +
  labs(title = "Principal Component Analysis of Ultimate Data")
```

We are fitting all three models that predict continuous variables: linear, LASSO, and ridge regression. Based on the results, we will select the model that is most accurate. Additionally, although the EDA for a player's +/- score seems similar for division and gender, there are slight differences; therefore, we will fit the model for each combination of division and gender.

# Results

```{python}
ultimate_data = r.ultimate_data

import pandas as pd
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
```

### *Ridge Regression* 

#### Function to Fit Model to Complete Data Set

```{python}
def ridge_reg(ultimate_data, alpha=1.0, test_size=0.2, random_state=42):
    # Define features and target
    feature_cols = ['turns_per_game', 'ds_per_game', 'ast_per_game', 'pts_per_game']
    target_col = 'pls_mns_per_game'

    # Drop rows with missing values
    data_clean = ultimate_data[feature_cols + [target_col]].dropna()

    # Separate X and y
    X = data_clean[feature_cols]
    y = data_clean[target_col]

    # Standardize features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Train/test split
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, random_state=random_state)

    # Train Ridge Regression
    model = Ridge(alpha=alpha)
    model.fit(X_train, y_train)

    # Output
    score = model.score(X_test, y_test)
    coef = dict(zip(feature_cols, model.coef_))
    intercept = model.intercept_

    return {
        'model': model,
        'score (R^2)': score,
        'coefficients': coef,
        'intercept': intercept,
        'scaler': scaler
    }
```

```{python}
results = ridge_reg(ultimate_data)

print("R² Score:", results['score (R^2)'])
print("Coefficients:", results['coefficients'])
print("Intercept:", results['intercept'])
```

#### Function to Fit Model by Division and Gender

```{python}
def ridge_by_div_gender(ultimate_data, alpha=1.0, test_size=0.2, random_state=42):
    feature_cols = ['turns_per_game', 'ds_per_game', 'ast_per_game', 'pts_per_game']
    target_col = 'pls_mns_per_game'

    results = {}

    # Group by actual column values
    for (division, gender), group in ultimate_data.groupby(['level', 'gender']):
        group_clean = group[feature_cols + [target_col]].dropna()

        if len(group_clean) < 5:
            continue  # Skip small groups

        X = group_clean[feature_cols]
        y = group_clean[target_col]

        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=test_size, random_state=random_state
        )

        model = Ridge(alpha=alpha)
        model.fit(X_train, y_train)

        results[(division, gender)] = {
            'model': model,
            'score (R^2)': model.score(X_test, y_test),
            'coefficients': dict(zip(feature_cols, model.coef_)),
            'intercept': model.intercept_,
            'scaler': scaler,
            'n_samples': len(group_clean)
        }

    return results
```

```{python}
resultsdg = ridge_by_div_gender(ultimate_data)

for (level, gender), res in resultsdg.items():
    print(f"{level} {gender} — R²: {res['score (R^2)']:.3f}")
    for feat, coef in res['coefficients'].items():
        print(f"    {feat}: {coef:.3f}")
    print()
```

#### *Plotting Feature Contributions*

```{python}
def plot_feature_contributions(results):
  
    sns.set(style="whitegrid")

    # For each group (level, gender), plot the feature coefficients
    for (level, gender), res in results.items():
        coefs = res['coefficients']
        
        # Sort features by absolute coefficient values
        sorted_feats = sorted(coefs.items(), key=lambda x: abs(x[1]), reverse=True)
        
        # Prepare data for plotting
        features = [feat for feat, _ in sorted_feats]
        coef_values = [coef for _, coef in sorted_feats]
        
        # Plot the bar chart
        plt.figure(figsize=(8, 6))
        plt.barh(features, coef_values, color="skyblue")
        plt.xlabel("Coefficient Value")
        plt.title(f"Feature Contributions: {level} {gender}")
        plt.tight_layout()
        plt.show()
```

```{python}
plot_feature_contributions(resultsdg)
```

#### **Prediction Model**

```{python}
def predict_plus_minus(ultimate_data, level, gender, player_stats, results):
    feature_cols = ['turns_per_game', 'ds_per_game', 'ast_per_game', 'pts_per_game']
    
    if (level, gender) not in results:
        raise ValueError(f"No model available for {level} {gender}")

    model = results[(level, gender)]['model']
    scaler = results[(level, gender)]['scaler']
    
    player_df = pd.DataFrame([player_stats], columns=feature_cols)
    player_data_scaled = scaler.transform(player_df)

    predicted_plus_minus = model.predict(player_data_scaled)[0]

    return predicted_plus_minus
```

#### *Example Use of Prediction Model - Using Filler D1 Men Stats* 

```{python}
player_stats = {
    'turns_per_game': 2.1,
    'ds_per_game': 1.8,
    'ast_per_game': 3.2,
    'pts_per_game': 5.4
}

# Get the results from Ridge regression (run the model first)
results = ridge_by_div_gender(ultimate_data)

# Predict for Division 1 Men
predicted_plus_minus_d1_men = predict_plus_minus(ultimate_data, 'Division 3', 'Men', player_stats, results)

print(f"Predicted +/- score per game (D1 Men): {predicted_plus_minus_d1_men:.2f}")
```

Showcase how you arrived at answers to your research question using the techniques we have learned in class (and beyond, if you’re feeling adventurous).

**Provide only the main results from your analysis.** The goal is not to do an exhaustive data analysis (calculate every possible statistic and perform every possible procedure for all variables). Rather, you should demonstrate that you are proficient at asking meaningful questions and answering them using data, that you are skilled in interpreting and presenting results, and that you can accomplish these tasks using R and Python. More is not always better.

#### Discussion

This section is a conclusion and discussion. This will require a summary of what you have learned about your research question along with statistical and methodological arguments supporting your conclusions. You should critique your own methods and provide suggestions for improving your analysis and future work.

You should also discuss issues pertaining to the reliability and validity of your data and the appropriateness of the analyses should also be discussed. You must include at least one paragraph discussing in what ways the training data you used limits any inferential conclusions or predictions for new data you can make.

Finally, discuss whether there may be any ethical concerns with your project. What are the benefits and risks associated with it?
