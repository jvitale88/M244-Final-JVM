---
title: "Untitled"
format: html
editor: visual
---

```{r}
library(here)
library(tidyverse)
library(ggplot2)
library(corrr)
library(ggcorrplot)
library(FactoMineR)
library(factoextra)
library(ggfortify)
library(cluster)
library(reticulate)
```

```{r}

# Load dataset
ultimate_data <- read_csv("/Users/miazottoli/Desktop/M244-Final-JVM/data/ultimate_college_championship.csv") %>%
# Standardise school names
  mutate(across(c(level, gender, division, team_name), as.factor)) %>%
  mutate(school = str_split_i(team_name, " ", 1)) %>%
  mutate(school = ifelse(str_detect(team_name, "St Olaf"), "St Olaf", school)) %>%
  mutate(school = ifelse(str_detect(team_name, "North Carolina"), "North Carolina", school)) %>%
  mutate(school = ifelse(str_detect(team_name, "Cal Poly"), "Cal Poly SLO", school))  %>%
  mutate(school = ifelse(str_detect(team_name, "British Columbia"), "British Columbia", school))  %>%
  mutate(school = ifelse(str_detect(team_name, "Western Washington"), "Western Washington", school))  %>%
  mutate(school = ifelse(str_detect(team_name, "Penn State"), "Penn State", school))  %>%
  mutate(school = ifelse(str_detect(team_name, "San Diego"), "UCSD", school))  %>%
  mutate(school = ifelse(str_detect(team_name, "Lewis"), "Lewis & Clark", school))  %>%
  mutate(school = ifelse(str_detect(team_name, "Colorado State"), "Colorado State", school))  %>%
  mutate(school = ifelse(str_detect(team_name, "Oklahoma Christian"), "Oklahoma Christian", school))  %>%
  mutate(school = ifelse(str_detect(team_name, "Binghamton"), "SUNY Binghamton", school))  %>%
  mutate(school = ifelse(str_detect(team_name, "Santa Bar"), "UCSB", school))  %>%
  mutate(school = ifelse(str_detect(team_name, "Santa Cr"), "USCS", school))  %>%
  mutate(school = ifelse(str_detect(team_name, "Colorado College"), "Colorado College", school))  %>%
  mutate(school = ifelse(str_detect(team_name, "Missouri S"), "Missouri S&T", school))  %>%
  mutate(school = ifelse(str_detect(team_name, "Holyoke"), "Mount Holyoke", school))  %>%
  mutate(school = ifelse(str_detect(team_name, "NC State"), "NC State", school))  %>%
  mutate(school = ifelse(str_detect(team_name, "Oregon State"), "Oregon State", school))  %>%
  mutate(school = ifelse(str_detect(team_name, "Washington University"), "Washington University", school))
```

```{r}
ultimate_data <- read_csv("/Users/miazottoli/Desktop/M244-Final-JVM/data/ulti_clean.csv")
```

### Ridge Regression 

```{python}
ultimate_data = r.ultimate_data
```

```{python}
import pandas as pd
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np
```

```{python}
def ridge_reg(ultimate_data, alpha=1.0, test_size=0.2, random_state=42):
    # Define features and target
    feature_cols = ['turns_per_game', 'ds_per_game', 'ast_per_game', 'pts_per_game']
    target_col = 'pls_mns_per_game'

    # Drop rows with missing values
    data_clean = ultimate_data[feature_cols + [target_col]].dropna()

    # Separate X and y
    X = data_clean[feature_cols]
    y = data_clean[target_col]

    # Standardize features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Train/test split
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, random_state=random_state)

    # Train Ridge Regression
    model = Ridge(alpha=alpha)
    model.fit(X_train, y_train)

    # Output
    score = model.score(X_test, y_test)
    coef = dict(zip(feature_cols, model.coef_))
    intercept = model.intercept_

    return {
        'model': model,
        'score (R^2)': score,
        'coefficients': coef,
        'intercept': intercept,
        'scaler': scaler
    }
```

**Results for Ridge Regression for Complete Dataset**

```{python}
results = ridge_reg(ultimate_data)

print("R² Score:", results['score (R^2)'])
print("Coefficients:", results['coefficients'])
print("Intercept:", results['intercept'])
```

### Function for grouped by division and gender 

```{python}
def ridge_by_div_gender(ultimate_data, alpha=1.0, test_size=0.2, random_state=42):
    feature_cols = ['turns_per_game', 'ds_per_game', 'ast_per_game', 'pts_per_game']
    target_col = 'pls_mns_per_game'

    results = {}

    # Group by actual column values
    for (division, gender), group in ultimate_data.groupby(['level', 'gender']):
        group_clean = group[feature_cols + [target_col]].dropna()

        if len(group_clean) < 5:
            continue  # Skip small groups

        X = group_clean[feature_cols]
        y = group_clean[target_col]

        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=test_size, random_state=random_state
        )

        model = Ridge(alpha=alpha)
        model.fit(X_train, y_train)

        results[(division, gender)] = {
            'model': model,
            'score (R^2)': model.score(X_test, y_test),
            'coefficients': dict(zip(feature_cols, model.coef_)),
            'intercept': model.intercept_,
            'scaler': scaler,
            'n_samples': len(group_clean)
        }

    return results

```

```{python}
resultsdg = ridge_by_div_gender(ultimate_data)

for (level, gender), res in resultsdg.items():
    print(f"{level} {gender} — R²: {res['score (R^2)']:.3f}")
    for feat, coef in res['coefficients'].items():
        print(f"    {feat}: {coef:.3f}")
    print()
```

```{python}
import matplotlib.pyplot as plt
import seaborn as sns

def plot_feature_contributions(results):
  
    sns.set(style="whitegrid")

    # For each group (level, gender), plot the feature coefficients
    for (level, gender), res in results.items():
        coefs = res['coefficients']
        
        # Sort features by absolute coefficient values
        sorted_feats = sorted(coefs.items(), key=lambda x: abs(x[1]), reverse=True)
        
        # Prepare data for plotting
        features = [feat for feat, _ in sorted_feats]
        coef_values = [coef for _, coef in sorted_feats]
        
        # Plot the bar chart
        plt.figure(figsize=(8, 6))
        plt.barh(features, coef_values, color="skyblue")
        plt.xlabel("Coefficient Value")
        plt.title(f"Feature Contributions: {level} {gender}")
        plt.tight_layout()
        plt.show()
```

```{python}
plot_feature_contributions(resultsdg)
```

**Prediction Model**

```{python}
def predict_plus_minus(ultimate_data, level, gender, player_stats, results):
    feature_cols = ['turns_per_game', 'ds_per_game', 'ast_per_game', 'pts_per_game']
    
    if (level, gender) not in results:
        raise ValueError(f"No model available for {level} {gender}")

    model = results[(level, gender)]['model']
    scaler = results[(level, gender)]['scaler']
    
    player_df = pd.DataFrame([player_stats], columns=feature_cols)
    player_data_scaled = scaler.transform(player_df)

    predicted_plus_minus = model.predict(player_data_scaled)[0]

    return predicted_plus_minus
```

### Example (use monk data?)

```{python}
player_stats = {
    'turns_per_game': 2.1,
    'ds_per_game': 1.8,
    'ast_per_game': 3.2,
    'pts_per_game': 5.4
}

# Get the results from Ridge regression (run the model first)
results = ridge_by_div_gender(ultimate_data)

# Predict for Division 1 Men
predicted_plus_minus_d1_men = predict_plus_minus(ultimate_data, 'Division 3', 'Men', player_stats, results)

print(f"Predicted +/- score per game (D1 Men): {predicted_plus_minus_d1_men:.2f}")
```
